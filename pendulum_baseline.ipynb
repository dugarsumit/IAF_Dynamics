{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named baseline",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f31ad1cc574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDVBF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mworld\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPendulumFullObs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named baseline"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from baseline import DVBF\n",
    "from world import PendulumFullObs\n",
    "\n",
    "def sample_batch(X, U, batch_size):\n",
    "    sample = np.random.rand(batch_size) * X.shape[1]\n",
    "    sample = sample.astype(int)\n",
    "\n",
    "    batch_x = X[:, sample]\n",
    "    batch_u = U[:, sample]\n",
    "    \n",
    "    return batch_x, batch_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "world = PendulumFullObs()\n",
    "X, U, R, S = world.get_data_set(episodes=500, steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "n_obs = 3\n",
    "n_control = 1\n",
    "n_latent =  6\n",
    "n_enc = 10\n",
    "learning_rate = 0.0005\n",
    "min_learning_rate = 0.00005\n",
    "decay_rate = 0.97\n",
    "m = DVBF(n_obs, n_control, n_latent, n_enc, learning_rate)\n",
    "\n",
    "# Training parameters\n",
    "training_epochs = 500\n",
    "batch_size = 16\n",
    "steps_per_epoch = X.shape[1] / batch_size\n",
    "display_step = 10\n",
    "\n",
    "epochs = []\n",
    "total_loss = []\n",
    "rec_loss = []\n",
    "kl_loss = []\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # Decay the learning rate\n",
    "    if learning_rate > min_learning_rate:\n",
    "        learning_rate *= decay_rate\n",
    "\n",
    "    # Train one epoch \n",
    "    avg_total_loss = .0\n",
    "    avg_kl_loss = .0\n",
    "    avg_rec_loss = .0\n",
    "    for i in range(steps_per_epoch):\n",
    "        batch_x, batch_u = sample_batch(X, U, batch_size)\n",
    "        temp_total_loss, temp_kl_loss, temp_rec_loss = m.train(batch_x, batch_u, learning_rate)\n",
    "        avg_total_loss += temp_total_loss\n",
    "        avg_kl_loss += temp_kl_loss\n",
    "        avg_rec_loss += temp_rec_loss\n",
    "    \n",
    "    avg_total_loss /= steps_per_epoch\n",
    "    avg_kl_loss /= steps_per_epoch\n",
    "    avg_rec_loss /= steps_per_epoch\n",
    "    \n",
    "    total_loss.append(avg_total_loss)\n",
    "    kl_loss.append(avg_kl_loss)\n",
    "    rec_loss.append(avg_rec_loss)\n",
    "    epochs.append(epoch)\n",
    "\n",
    "    # Plot the results\n",
    "    if epoch % display_step == 0:\n",
    "                \n",
    "        plt.close()\n",
    "        f, axarr = plt.subplots(1, 3, figsize=(13, 4))\n",
    "        axarr[0].plot(epochs, total_loss)\n",
    "        axarr[0].set_xlabel('Epochs')\n",
    "        axarr[0].set_title('Total Loss')\n",
    "        axarr[0].annotate(\"Learning Rate: \" + str(learning_rate), xy=(0.05, 0.05), xycoords='axes fraction')\n",
    "        axarr[0].set_ylim(-9.0, 10)\n",
    "        axarr[1].plot(epochs, rec_loss)\n",
    "        axarr[1].set_xlabel('Epochs')\n",
    "        axarr[1].set_title('Rec Loss')\n",
    "        axarr[1].set_ylim(-9.0, 10)\n",
    "        axarr[2].plot(epochs, kl_loss)\n",
    "        axarr[2].set_xlabel('Epochs')\n",
    "        axarr[2].set_title('KL Loss')\n",
    "        axarr[2].set_ylim(.0, 10)\n",
    "\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the true trajectory\n",
    "X_temp, U_temp, R_temp, S_temp = world.get_data_set(episodes=100)\n",
    "x_obs = m.sess.run((m.gen_x_mean), feed_dict={m.x: X_temp, m.u:U_temp})\n",
    "\n",
    "# Plot the position and reward of low dim pendulum\n",
    "e = int(np.random.rand() * 100)\n",
    "f, axarr = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axarr[0].plot(np.arctan2(x_obs[:, e, 1], x_obs[:, e, 0]))\n",
    "axarr[1].plot(np.arctan2(X_temp[:, e, 1], X_temp[:, e, 0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}